{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWJzjN61fqHVsFHpYl7yKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JDslay/LKA/blob/main/DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LomxrVtBG5At",
        "outputId": "3b2bcc37-1e6f-42a5-afae-80b83d5df7e4"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision import models\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import httpimport\r\n",
        "url = \"https://raw.githubusercontent.com/JDslay/LKA/main/resources\"\r\n",
        "with httpimport.remote_repo([\"plotcm\"], url):\r\n",
        "    import plotcm\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "import time\r\n",
        "import progressbar\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii8IbRbFJTnu"
      },
      "source": [
        "# some functions needed for the analysis\r\n",
        "\r\n",
        "# All predictions in one tensor\r\n",
        "@torch.no_grad()  # gradients not needed while evaluation / saves memory if turned off\r\n",
        "def get_all_preds(model, loader):\r\n",
        "    all_preds = torch.tensor([])\r\n",
        "    for batch in loader:\r\n",
        "        images, labels = batch\r\n",
        "        preds = model(images)\r\n",
        "        all_preds = torch.cat((all_preds, preds), dim=0)\r\n",
        "    return all_preds\r\n",
        "\r\n",
        "# Number of correct predictions\r\n",
        "def get_nbr_correct_predicted(preds, labels):\r\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxNrk1xeJxOV"
      },
      "source": [
        "# load data and prepare\r\n",
        "\r\n",
        "train_set = torchvision.datasets.ImageFolder(\r\n",
        "    root='/content/drive/MyDrive/ColabNotebooks/data/40_tobacco/train', transform=transforms.Compose([\r\n",
        "        transforms.Resize((227, 227)),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])\r\n",
        ")\r\n",
        "batchSze = 100\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batchSze)  # getting batches out of dataset"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3B80nnzKViD"
      },
      "source": [
        "# load pretrained alexnet and prepare for finetuning\r\n",
        "\r\n",
        "alexNetMod = models.alexnet(pretrained=True)\r\n",
        "\r\n",
        "# freeze parameters\r\n",
        "for param in alexNetMod.parameters():\r\n",
        "    param.requires_grad = False\r\n",
        "\r\n",
        "# change last fully connected layer with new and 10 outputs\r\n",
        "alexNetMod.classifier[6] = nn.Linear(4096, 10)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvkAuzleLTIL"
      },
      "source": [
        "# TRAIN MODEL\r\n",
        "optimizer = optim.RMSprop(alexNetMod.parameters(\r\n",
        "), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0.0005, momentum=0.9, centered=False)\r\n",
        "\r\n",
        "\r\n",
        "epochs = 2\r\n",
        "bar = progressbar.ProgressBar(max_value=len(train_set)/batchSze*epochs)\r\n",
        "i = 0\r\n",
        "# training loop\r\n",
        "for epoch in range(2):\r\n",
        "    total_loss = 0\r\n",
        "    total_correct = 0\r\n",
        "    for batch in train_loader:                  # Get Batch\r\n",
        "        images, labels = batch\r\n",
        "        preds = alexNetMod(images)                 # Pass Batch\r\n",
        "        loss = F.cross_entropy(preds, labels)   # Calculate Loss\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()                         # Calculate Gradient\r\n",
        "        optimizer.step()                        # Updating weights\r\n",
        "        total_loss += loss.item()\r\n",
        "        total_correct += get_nbr_correct_predicted(preds, labels)\r\n",
        "        i+=1\r\n",
        "        bar.update(i)\r\n",
        "    print('epoch:', epoch, 'total_correct:',\r\n",
        "          total_correct, \"loss:\", total_loss)\r\n",
        "\r\n",
        "print(total_correct/len(train_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0akFqsH0LsaU"
      },
      "source": [
        "# Predict all images\r\n",
        "train_preds = get_all_preds(alexNetMod, train_loader)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p19D1OI0xgCQ",
        "outputId": "9bc577dc-416c-4792-c40b-c39f70eb195f"
      },
      "source": [
        "labeltensor = torch.tensor(train_set.targets)\r\n",
        "preds_correct = get_nbr_correct_predicted(train_preds, labeltensor)\r\n",
        "print('total correct:', preds_correct, 'out of ', len(train_set))\r\n",
        "print('accuracy: ', preds_correct / len(train_set))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total correct: 232 out of  400\n",
            "accuracy:  0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Wwd1QEwt5M"
      },
      "source": [
        "# Show confusion matrix\r\n",
        "cm = confusion_matrix(labeltensor, train_preds.argmax(dim=1))\r\n",
        "names = ('ADVE', 'Email', 'Form', 'Letter', 'Memo',\r\n",
        "         'News', 'Note', 'Report', 'Resume', 'Scientific')\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "plotcm.plot_confusion_matrix(cm, names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}