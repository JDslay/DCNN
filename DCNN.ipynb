{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiDaRWj3nM5j/EIqvFT2EW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59a34d20992b4d40bf9f3054155cffe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76c795eab4254708b9f3936026ac3542",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9269fb67dbb4b03ae06bc3cd87ffaa4",
              "IPY_MODEL_449f7e175b52498d9eaf340cc3db8406"
            ]
          }
        },
        "76c795eab4254708b9f3936026ac3542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9269fb67dbb4b03ae06bc3cd87ffaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5768cf17575547dbaba42cde79d1f7e4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_475e0e7964e1452e8fa64c3a7e0a7eb6"
          }
        },
        "449f7e175b52498d9eaf340cc3db8406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c0748f7f1d04b93ba1329128469b762",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [04:46&lt;00:00, 853kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_676de086ed9647aaaa9e9601937cca5f"
          }
        },
        "5768cf17575547dbaba42cde79d1f7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "475e0e7964e1452e8fa64c3a7e0a7eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c0748f7f1d04b93ba1329128469b762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "676de086ed9647aaaa9e9601937cca5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JDslay/LKA/blob/main/DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fitpwr28S_Ku"
      },
      "source": [
        "# Finetuning of pretrained AlexNet (on ImageNet-Dataset) with Tobacco3482-Dataset \r\n",
        "Initially the AlexNet was trained with the purpose of classifying images into 1000 categories like cat and dog.\r\n",
        "This notebook retraines the last fully connected layer of AlexNet on images of documents to categorize 10 classes (ADVE, Email, Form, Letter, Memo, News, Note, Report, Resume, Scientific)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-btsG8ZJWoIU"
      },
      "source": [
        "In the import section the file for plotting the confusion matrix is imported from my Github-Repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LomxrVtBG5At"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision import models\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import httpimport\r\n",
        "url = \"https://raw.githubusercontent.com/JDslay/LKA/main/resources\"     # from deeplizard.com respectively scikit-learn.org\r\n",
        "with httpimport.remote_repo([\"plotcm\"], url):\r\n",
        "    import plotcm                                        \r\n",
        "import time\r\n",
        "import progressbar"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfzj1aObBvP2"
      },
      "source": [
        "For testing purposes, data of my Google Drive have been mounted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfUj9UoeBny7",
        "outputId": "a41847f4-6f2d-4cdd-f775-1889272bb5fb"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')  "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSO3esQZXbk2"
      },
      "source": [
        "Later used functions for the evaluation of the model have to be initialized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii8IbRbFJTnu"
      },
      "source": [
        "# All predictions in one tensor\r\n",
        "@torch.no_grad()                                                        # gradients not needed while evaluation / saves memory if turned off\r\n",
        "def get_all_preds(model, loader):\r\n",
        "    all_preds = torch.tensor([])\r\n",
        "    for batch in loader:\r\n",
        "        images, labels = batch\r\n",
        "        preds = model(images)\r\n",
        "        all_preds = torch.cat((all_preds, preds), dim=0)\r\n",
        "    return all_preds\r\n",
        "\r\n",
        "# Number of correct predictions\r\n",
        "def get_nbr_correct_predicted(preds, labels):\r\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fq1x8ppHqV5"
      },
      "source": [
        "# Load the training and validation datasets, prepare the data and initialize a data-loader for ease of handling data\r\n",
        "The datastructure is essential. If training the model with 40 images of each class, a train folder with 10 subfolders each including 40 samples is crucial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxNrk1xeJxOV"
      },
      "source": [
        "# load data and prepare\r\n",
        "train_set = torchvision.datasets.ImageFolder(\r\n",
        "    root='/content/drive/MyDrive/ColabNotebooks/data/40_tobacco/train', transform=transforms.Compose([\r\n",
        "        transforms.Resize((227, 227)),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])\r\n",
        ")\r\n",
        "val_set = torchvision.datasets.ImageFolder(\r\n",
        "        root='/content/drive/MyDrive/ColabNotebooks/data/40_tobacco/val', transform=transforms.Compose([\r\n",
        "            transforms.Resize((227, 227)),\r\n",
        "            transforms.ToTensor(),\r\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "        ])\r\n",
        "    )\r\n",
        "batchSze = 10               # also needed later in calculation of preogress bar\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batchSze, shuffle=True)  # getting shuffeled batches out of dataset\r\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100)                   # no shuffling needed for evaluation"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taxdoNkoa5Bl"
      },
      "source": [
        "# Get the pretrained AlexNet model and retrain the last fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "59a34d20992b4d40bf9f3054155cffe6",
            "76c795eab4254708b9f3936026ac3542",
            "a9269fb67dbb4b03ae06bc3cd87ffaa4",
            "449f7e175b52498d9eaf340cc3db8406",
            "5768cf17575547dbaba42cde79d1f7e4",
            "475e0e7964e1452e8fa64c3a7e0a7eb6",
            "0c0748f7f1d04b93ba1329128469b762",
            "676de086ed9647aaaa9e9601937cca5f"
          ]
        },
        "id": "h3B80nnzKViD",
        "outputId": "8f5e4fd6-3610-4184-e989-9454091883d8"
      },
      "source": [
        "# load pretrained alexnet and prepare for finetuning\r\n",
        "alexNetMod = models.alexnet(pretrained=True)\r\n",
        "\r\n",
        "# freeze parameters\r\n",
        "for param in alexNetMod.parameters():\r\n",
        "    param.requires_grad = False\r\n",
        "\r\n",
        "# change last fully connected layer with new and 10 outputs\r\n",
        "alexNetMod.classifier[6] = nn.Linear(4096, 10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59a34d20992b4d40bf9f3054155cffe6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctfzv0PibLkM"
      },
      "source": [
        "# Retrain the last layer of the modified AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvkAuzleLTIL"
      },
      "source": [
        "# TRAIN MODEL\r\n",
        "optimizer = optim.SGD(alexNetMod.parameters(), lr=0.0001,momentum=0.9, weight_decay=0.0005)\r\n",
        "\r\n",
        "epochs = 3\r\n",
        "bar = progressbar.ProgressBar(max_value=len(train_set)/batchSze*epochs)\r\n",
        "i = 0\r\n",
        "# training loop\r\n",
        "for epoch in range(epochs):\r\n",
        "    total_loss = 0\r\n",
        "    total_correct = 0\r\n",
        "    for batch in train_loader:                  # Get Batch\r\n",
        "        images, labels = batch                  # unpack batch\r\n",
        "        preds = alexNetMod(images)              # pass Batch\r\n",
        "        loss = F.cross_entropy(preds, labels)   # calculate Loss\r\n",
        "        optimizer.zero_grad()                   # set gradients to zero  \r\n",
        "        loss.backward()                         # calculate gradients\r\n",
        "        optimizer.step()                        # Updating weights\r\n",
        "        \r\n",
        "        # show progress of training visually and numercally  \r\n",
        "        i+=1\r\n",
        "        bar.update(i)\r\n",
        "        total_loss += loss.item()                \r\n",
        "        total_correct += get_nbr_correct_predicted(preds, labels)   \r\n",
        "    print('   epoch:', epoch, 'total_correct:',total_correct, \"loss:\", total_loss)\r\n",
        "\r\n",
        "# show results of training\r\n",
        "correct_train_perc = 100*total_correct/len(train_set)\r\n",
        "print('percentage of correct predictions within training', correct_train_perc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyqRTUEweo6Z"
      },
      "source": [
        "# Evaluate the retrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0akFqsH0LsaU"
      },
      "source": [
        "# Predict all images\r\n",
        "val_preds = get_all_preds(alexNetMod, val_loader)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p19D1OI0xgCQ"
      },
      "source": [
        "# print number of correct predictions and accuracy \r\n",
        "labeltensor = torch.tensor(val_set.targets)\r\n",
        "preds_correct = get_nbr_correct_predicted(val_preds, labeltensor)\r\n",
        "print('total correct:', preds_correct, 'out of ', len(val_set), 'documents')\r\n",
        "print('accuracy: ', 100*preds_correct / len(val_set), '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Wwd1QEwt5M"
      },
      "source": [
        "# Show confusion matrix\r\n",
        "cm = confusion_matrix(labeltensor, train_preds.argmax(dim=1))\r\n",
        "names = ('ADVE', 'Email', 'Form', 'Letter', 'Memo',\r\n",
        "         'News', 'Note', 'Report', 'Resume', 'Scientific')\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "plotcm.plot_confusion_matrix(cm, names, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}